**Procedure**

**1. Receipt of sequencing files**
   
Sequencing files are automatically imported onto the staging server upon completion of an Illumina sequencing run. The bioinformatics production server checks the staging server for completed runs every 10 minutes via a scheduled cron job. When a new completed run is detected, the production server automatically imports the files from the staging server to ``/mnt/data/raw/<SEQUENCER_ID>/<RUN_ID>/`` and initiates the bioinformatics QC pipeline, which is implemented in Nextflow and maintained on `GitHub <https://github.com/lab-bioinformatics/qc-pipeline>`_.

.. raw:: html

   <hr>

**2. Executing the analysis**
   
The bioinformatics QC pipeline can be executed in two modes: 

1.	**Automated Mode:** The pipeline is launched automatically when a new sequencing run is copied from the staging server.
2.	**Manual Mode:** A user can manually initiate the pipeline on a selected set of FASTQ files.

Detailed instructures for launching the pipeline in manual mode are provided below:

**2.1 Manual Mode**

Manual mode should only be used where a run has failed because of a server issue (e.g. a power cut that stopped the analysis part way through) or because sequence data needs to be imported from another source (e.g. where fastq files have been generated by a collaborating organisation and we wish to be able to analyse the locally within the laboratory).

.. note::
    Manual mode can only be initiated by a member of the bioinformatics team as access to servers is restricted.

To restart a failed run:

Log into the production server using an ssh client and switch to a user profile with appropriate permissions:

.. code-block:: bash

    ssh username@10.0.1.12
    sudo su - prod-user

Access to the server is restricted and can only be made from within the laboratory network. Users must either be connected via a wired network connection or have an active VPN session to reach the server.

If the samples were sequenced in-house, navigate to the directory for the relevant sequencing run by changing into the appropriate path, for example:

.. code-block:: bash
    cd /mnt/data/raw/<SEQUENCER_ID>/<RUN_ID>/Data/Intensities/BaseCalls/

Once in the directory, verify that FASTQ files are present by listing them:

.. code-block:: bash
    ls *.fastq.qz

This command will display all FASTQ files in the directory. If no FASTQ files are found, first check whether the sequencing run has completed. If the run has finished and no FASTQ files are present, the sequencing run or the file transfer may have failed. In this case, refer to **SOP045: Using the NextSeq 550 for further guidance**.

If FASTQ files are present for all expected samples within a run, you are ready to run the QC pipeline on them. To manually initiate the bioinformatics QC pipeline on the FASTQ files, run the following command from within the run-level directory:

.. code-block:: bash
    nextflow run /path/to/qc_pipeline.nf \
        --input /mnt/data/raw/<SEQUENCER_ID>/<RUN_ID> \
        -profile prod,slurm

The QC pipeline will now be submitted to the production job queue. Because Nextflow launches one Slurm job per process (or per task if parallelised), multiple jobs will appear in the queue. The status of these jobs can be monitored using:

   .. code-block:: bash
      squeue -u prod-user

Once sufficient compute resources become available, the job scheduler will start the pipeline. The scheduler is configured so that jobs allocated to the production queue are prioritised; therefore, the QC pipeline should normally commence within a few minutes, depending on resource availability.

.. raw:: html

   <hr>


**3. Pipeline completion**

The bioinformatics QC pipeline completes the following steps:

   1.	Pairs fastq files based on their name using pattern matching to identify which samples are “forward” and which are “reverse”.
   
   2.	Identifies the workstream associated with each FASTQ file based on the prefix in the sample name (e.g. FLU for the flu workstream, SARS for the SARS workstream).

   3.	Reads the FASTQ files to extract metadata including run ID, flowcell ID, and sequencing instrument.
   
   4.	Checks whether a directory for that run already exists within the relevant workstream folder (e.g. ``/mnt/data/analysis/flu/<RUN_ID>/``); if not, it creates one.
   
   5.	Creates a backup copy of the raw sequencing data on cold storage (/mnt/archive/raw/<SEQUENCER_ID>/<RUN_ID>/).
   
   6.	Runs Cutadapt and FastQC (via the Trim Galore! wrapper), producing trimmed FASTQ files and QC reports, which are stored in the qc subfolder.
   
   7.	Screens the trimmed FASTQ files using Centrifuge against a reference database of Human, Bacterial, Viral, and Archaeal genomes.
   
   8.	Generates a graphical representation of sample content using Krona, based on Centrifuge output, and stores it in the run folder.
   
   9.	Collates all QC outputs (from Cutadapt and FastQC) into a single report using MultiQC.

Once the analysis has completed, results are written to workstream specific subdirectories under the qc folder: ``/mnt/data/analysis/<WORKSTREAM>/<RUN_ID>/qc``. Within this directory, the following subdirectories are generated:

**MultiQC Report**

``/mnt/data/analysis/<WORKSTREAM>/<RUN_ID>/qc/multiqc/``

Contains the consolidated QC summary (multiqc_report.html), which collates metrics across all workstream specific sequencing files processed in the run.

**Trimmed Reads**

``/mnt/data/analysis/<WORKSTREAM>/<RUN_ID>/qc/trimmed_reads/``

Contains adapter trimmed FASTQ files. These cleaned reads are suitable for downstream analyses such as alignment, variant calling, or further project specific workflows.

**Centrifuge Report**

``/mnt/data/analysis/<WORKSTREAM>/<RUN_ID>/qc/centrifuge/``

Contains a graphic report summarising the species assignments of reads that could be classified using Centrifuge.

.. raw:: html

   <hr>

**4. *Interpreting the analysis report*

...